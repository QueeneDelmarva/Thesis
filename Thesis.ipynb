{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QueeneDelmarva/Thesis/blob/Debugging-Radix-Trie/Thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuXjnvCDUNzk"
      },
      "source": [
        "# **Thesis Code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA2DqlMRUwCX"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "XbNhQF4XUJRc"
      },
      "outputs": [],
      "source": [
        "# Connect to Gdrive\n",
        "from google.colab import drive\n",
        "\n",
        "# Connect to Gsheets\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "# Preprocessing\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "# Edit Distance\n",
        "import Levenshtein\n",
        "\n",
        "# Generate Misspellings\n",
        "import random\n",
        "import string\n",
        "\n",
        "# GUI\n",
        "import tkinter as tk\n",
        "import tkinter.font as tkFont\n",
        "\n",
        "import string\n",
        "from google.colab import auth\n",
        "from google.auth import default"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install python-Levenshtein\n"
      ],
      "metadata": {
        "id": "jBQoMsLMwiOR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoNysK_-Xwnx"
      },
      "source": [
        "## Connecting to Gdrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ONK66ZwtXwtD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c6ccfe6-78c1-490f-84fb-a3b8c8244c6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXJU0KlqU7EF"
      },
      "source": [
        "## Connecting to GSheets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-OYarUCrU7Sr"
      },
      "outputs": [],
      "source": [
        "# Define the scope and create the credentials using the file in your Google Drive\n",
        "scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_name('/content/drive/MyDrive/skripsi-394804-a98ea9715aa4.json', scope)\n",
        "\n",
        "# Authenticate with gspread\n",
        "client = gspread.authorize(creds)\n",
        "\n",
        "# Open the Google Sheet by its title or URL\n",
        "spreadsheet_key = '1RlZ8-XwwEueuCAq4nXGwq3ZmPDE-_0gP3PsroKeNFGo'\n",
        "sheet = client.open_by_key(spreadsheet_key).sheet1\n",
        "\n",
        "# Open the train_data Google Sheet by its title or URL for writing\n",
        "train_data_sheet = client.open_by_key(spreadsheet_key).worksheet('train_data')\n",
        "test_data_sheet = client.open_by_key(spreadsheet_key).worksheet('test_data')\n",
        "\n",
        "# ## Read the data from the Gsheets\n",
        "# # 1. Read individual cells\n",
        "# cell_value = sheet.cell(3, 5).value\n",
        "# print(cell_value)\n",
        "\n",
        "# # 2. Read all values from the first worksheet\n",
        "# data = sheet.get_all_values()\n",
        "\n",
        "# # Print the data\n",
        "# for row in data:\n",
        "#     print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaSWQ06nhAvH"
      },
      "source": [
        "## Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6eRtztjshA7P"
      },
      "outputs": [],
      "source": [
        "# preprocess_dictonary = ['Noted', 'and', 'thanks', 'Please', 'as', 'follows', 'Copied']\n",
        "\n",
        "def preprocess(word):\n",
        "    # Separate words based on non-alphabetic characters\n",
        "    words = re.findall(r'\\b(?:[a-zA-Z0-9]+)\\b', word)\n",
        "\n",
        "    # Convert words to lowercase\n",
        "    lowercase_words = [w.lower() for w in words]\n",
        "\n",
        "    return lowercase_words\n",
        "\n",
        "    # Add preprocess dictonary to the list of preprocessed words\n",
        "    # preprocessed_words = lowercase_words + [g for g in preprocess_dictonary if g in word.lower()]\n",
        "\n",
        "    # return preprocessed_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZjAa09wctzp"
      },
      "source": [
        "### Radix Trie Node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xgsecwRqcNLa"
      },
      "outputs": [],
      "source": [
        "# Defines a class representing a single node in the radix trie, holding information about its children and whether it marks the end of a word.\n",
        "class RadixTrieNode:\n",
        "    def __init__(self):\n",
        "        self.children = {}\n",
        "        self.is_end_of_word = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1WQWZ3xWTrv"
      },
      "source": [
        "### Hashmap-based Trie Node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7m3jFQTxWT0S"
      },
      "outputs": [],
      "source": [
        "# Defines a class representing a single node in the radix trie, holding information about its children and whether it marks the end of a word.\n",
        "class HashmapTrieNode:\n",
        "    def __init__(self):\n",
        "        self.children = {}\n",
        "        self.is_end_of_word = False\n",
        "        self.char = \"\"  # Add this line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvwBCoNActvv"
      },
      "source": [
        "### Radix Trie Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "GHu5eLPQctnc"
      },
      "outputs": [],
      "source": [
        "# Defines a class that implements a radix trie data structure, allowing efficient storage and retrieval of a set of strings with common prefixes.\n",
        "class RadixTrie:\n",
        "    def __init__(self):\n",
        "        self.root = RadixTrieNode()\n",
        "\n",
        "    # Adds a word to the Radix Trie by creating or traversing the appropriate nodes for each character in the word.\n",
        "    def insert(self, word):\n",
        "        node = self.root\n",
        "        for char in word:\n",
        "            if char not in node.children:\n",
        "                node.children[char] = RadixTrieNode()\n",
        "            node = node.children[char]\n",
        "        node.is_end_of_word = True\n",
        "\n",
        "    # Finds all words in the Radix Trie that have the given prefix, returning them as a list of results.\n",
        "    def search(self, prefix):\n",
        "        node = self.root\n",
        "        for char in prefix:\n",
        "            if char not in node.children:\n",
        "                return []  # Prefix not found, return an empty list\n",
        "            node = node.children[char]\n",
        "        return self.collect_words(node, prefix)\n",
        "\n",
        "   # Recursively explores the Radix Trie's child nodes and appends the complete words to the results list when reaching the end of a word.\n",
        "    def collect_words(self, node, prefix, words):\n",
        "      # Base case: If the node is an end node, add the word to the list\n",
        "      if node.is_end_of_word:\n",
        "        words.append(prefix)\n",
        "\n",
        "      # Recursively traverse all child nodes\n",
        "      for char, child in node.children.items():\n",
        "        self.collect_words(child, prefix + char, words)  # Use 'child' instead of 'child_node'\n",
        "\n",
        "      return words\n",
        "\n",
        "    def get_all_words(self):\n",
        "      words = []\n",
        "      self.collect_words(self.root, \"\", words)\n",
        "      return words\n",
        "\n",
        "    def visualize(self, node, prefix, row_index, column_index):\n",
        "      if node.is_end_of_word:\n",
        "        output = prefix + \" end of word\"\n",
        "        print(output)\n",
        "        train_data_sheet.update_cell(row_index, column_index, output)\n",
        "        row_index += 1\n",
        "\n",
        "      for char, child in node.children.items():\n",
        "        if char != prefix:\n",
        "            output = prefix + \"| \" + char + \" -->\"\n",
        "            print(output)\n",
        "            train_data_sheet.update_cell(row_index, column_index, output)\n",
        "            self.visualize(child, prefix + \"| \", row_index + 1, column_index)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrvnOAoDZ0vm"
      },
      "source": [
        "### Hashmap-based Trie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "MZHzghuJZ0_P"
      },
      "outputs": [],
      "source": [
        "# Define a class represents a trie data structure that uses a hashmap to store children nodes, allowing efficient storage and retrieval of a set of strings with common prefixes.\n",
        "class HashmapTrie:\n",
        "    def __init__(self):\n",
        "        self.root = HashmapTrieNode()\n",
        "\n",
        "# Adds a word to the trie by traversing and creating nodes for each character in the word and marking the last node as the end of the word.\n",
        "    def insert(self, word):\n",
        "        node = self.root\n",
        "        for char in word:\n",
        "            if char not in node.children:\n",
        "                node.children[char] = HashmapTrieNode()\n",
        "            node = node.children[char]\n",
        "        node.is_end_of_word = True\n",
        "\n",
        "# Checks if a given prefix exists in the trie by traversing the nodes based on the characters of the prefix and returns whether the last node reached marks the end of a word.\n",
        "    def search(self, prefix):\n",
        "        node = self.root\n",
        "        for char in prefix:\n",
        "            if char not in node.children:\n",
        "                return []  # Prefix not found, return an empty list\n",
        "            node = node.children[char]\n",
        "        return self.collect_words(node, prefix)\n",
        "\n",
        "# Recursively traverses its child nodes and appends the complete words to the results list when reaching the end of a word.\n",
        "    def collect_words(self, node, current_prefix):\n",
        "        results = []\n",
        "        if node.is_end_of_word:\n",
        "            results.append(current_prefix)\n",
        "        for char, child in node.children.items():\n",
        "            word = current_prefix + char\n",
        "            results.extend(self.collect_words(child, word))\n",
        "        return results\n",
        "\n",
        "# Returns all words stored in the trie by collecting words\n",
        "    def get_all_words(self):\n",
        "        return self.collect_words(self.root, \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgLJc-4mLSaM"
      },
      "source": [
        "### Autocorrect with Levenshtein Edit Distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "cqCB_rlfLSRB"
      },
      "outputs": [],
      "source": [
        "class Autocorrect:\n",
        "    def __init__(self, trie):\n",
        "        self.trie = trie\n",
        "\n",
        "    def correct(self, word, threshold=0.9):  # Adjust threshold as needed\n",
        "        word = word.lower()\n",
        "        suggestions = []\n",
        "\n",
        "        # Traverse the trie to find similar words\n",
        "        similar_words = self.trie.search_similar(word)\n",
        "\n",
        "        # Calculate Jaro-Winkler distance and filter based on threshold\n",
        "        for similar_word in similar_words:\n",
        "            similarity = distance.get_jaro_distance(word, similar_word)\n",
        "            if similarity >= threshold:\n",
        "                suggestions.append(similar_word)\n",
        "\n",
        "        if suggestions:\n",
        "            return suggestions[0]  # Return the first suggestion\n",
        "        else:\n",
        "            return None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Misspellings"
      ],
      "metadata": {
        "id": "J7j8wSUq1H0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MisspelledWordGenerator:\n",
        "    def __init__(self, threshold=0.2):\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def generate(self, word):\n",
        "        misspelled_word = []\n",
        "        for char in word:\n",
        "            if random.random() < self.threshold:\n",
        "                misspelled_word.append(random.choice(string.ascii_lowercase))\n",
        "            else:\n",
        "                misspelled_word.append(char)\n",
        "        return ''.join(misspelled_word)"
      ],
      "metadata": {
        "id": "TzVtNDue1H8C"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weight Parameters"
      ],
      "metadata": {
        "id": "c53ZOdVlUxun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightEvaluator:\n",
        "    def __init__(self, trie_structure, weight_ranges):\n",
        "        self.trie_structure = trie_structure\n",
        "        self.weight_ranges = weight_ranges\n",
        "\n",
        "    def evaluate_weights(self, threshold):\n",
        "        print(\"Weightage | Accuracy | MMR\")\n",
        "\n",
        "        for w1, w2, w3 in self.weight_ranges:\n",
        "            accuracy, mmr = self.trie_structure.evaluate_performance(threshold, w1, w2, w3)\n",
        "            print(f\"{w1:.2f}, {w2:.2f}, {w3:.2f} | {accuracy:.3f} | {mmr:.3f}\")"
      ],
      "metadata": {
        "id": "iTYarXKhUx2p"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance Evaluation"
      ],
      "metadata": {
        "id": "UYLZH7Mgn6WC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EvaluationPerformance:\n",
        "    def __init__(self, trie_structure, weight_settings):\n",
        "        self.trie_structure = trie_structure\n",
        "        self.w1, self.w2, self.w3 = weight_settings\n",
        "\n",
        "    def calculate_prefix_score(self, word, dictionary):\n",
        "    # Print the data types of word and terms in dictionary\n",
        "        # print(\"Word data type:\", type(word))\n",
        "        # print(\"Term data type in dictionary:\", [type(term) for term in dictionary])\n",
        "        # Calculate and return the prefix score for the word and dictionary\n",
        "        prefix_score = 0\n",
        "        for term in dictionary:\n",
        "            if term.startswith(word):\n",
        "                prefix_score += len(word)\n",
        "        return prefix_score\n",
        "\n",
        "    def calculate_suffix_score(self, word, dictionary):\n",
        "        # Calculate and return the suffix score for the word and dictionary\n",
        "        suffix_score = 0\n",
        "        for term in dictionary:\n",
        "            reversed_term = term[::-1]\n",
        "            reversed_word = word[::-1]\n",
        "            if reversed_term.startswith(reversed_word):\n",
        "                suffix_score += len(reversed_word)\n",
        "        return suffix_score\n",
        "\n",
        "    def calculate_similarity_score(self, word, term):\n",
        "      lcs = self.LongestCommonSubsequence(word, term)\n",
        "      similarity_score = (2 * lcs) / (len(word) + len(term))\n",
        "      # print(f\"Word: {word}, Term: {term}, LCS: {lcs}, Similarity Score: {similarity_score}\")\n",
        "      return similarity_score\n",
        "\n",
        "\n",
        "    def LongestCommonSubsequence(self, text1, text2):\n",
        "        m, n = len(text1), len(text2)\n",
        "        dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "\n",
        "        for i in range(1, m + 1):\n",
        "            for j in range(1, n + 1):\n",
        "                if text1[i - 1] == text2[j - 1]:\n",
        "                    dp[i][j] = dp[i - 1][j - 1] + 1\n",
        "                else:\n",
        "                    dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
        "\n",
        "        return dp[m][n]\n",
        "\n",
        "    def evaluate(self, test_data):\n",
        "      results = []\n",
        "      for query, correct_term in test_data:\n",
        "            # print(\"Query:\", query, \"Correct Term:\", correct_term)\n",
        "            dictionary = self.trie_structure.get_all_words()\n",
        "            # print(\"Dictionary:\", dictionary)\n",
        "            # print(\"Correct Term:\", correct_term)\n",
        "            prefix_score = self.calculate_prefix_score(query, dictionary)\n",
        "            suffix_score = self.calculate_suffix_score(query, dictionary)\n",
        "            similarity_score = self.calculate_similarity_score(query, correct_term)\n",
        "\n",
        "            # Calculate the overall score based on weights w1, w2, and w3\n",
        "            overall_score = (self.w1 * prefix_score) + (self.w2 * suffix_score) + (self.w3 * similarity_score)\n",
        "\n",
        "            results.append((query, correct_term, overall_score, prefix_score, suffix_score, similarity_score))\n",
        "\n",
        "            # print(f\"Query: {query}, Correct Term: {correct_term}\")\n",
        "            # print(f\"Prefix Score: {prefix_score}, Suffix Score: {suffix_score}, Similarity Score: {similarity_score}\")\n",
        "\n",
        "      return results"
      ],
      "metadata": {
        "id": "cnfO-rB9n6j1"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0GsjWoqVe29"
      },
      "source": [
        "### **Main Function**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Create a Radix Trie\n",
        "    trie = RadixTrie()\n",
        "    words = [\"and\", \"acam\", \"as\"]\n",
        "    for word in words:\n",
        "        trie.insert(word)\n",
        "\n",
        "    # Visualize the Radix Trie for each letter\n",
        "    for letter in trie.root.children:\n",
        "        print(letter)\n",
        "        output = letter + \" -->\"\n",
        "        column_index = 3  # Initialize column_index here\n",
        "        row_index = 2     # Initialize row_index here\n",
        "        print(output)\n",
        "        train_data_sheet.update_cell(row_index, column_index, output)\n",
        "        trie.visualize(trie.root.children[letter], \"\", row_index + 1, column_index)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFtF4SJSXYYK",
        "outputId": "13291527-c34e-41f8-c8d2-52f0d63cc8b6"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\n",
            "a -->\n",
            "| n -->\n",
            "| | d -->\n",
            "| |  end of word\n",
            "| c -->\n",
            "| | a -->\n",
            "| | | m -->\n",
            "| | |  end of word\n",
            "| s -->\n",
            "|  end of word\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "5VoBr7nSVert",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "35df82be-ca32-478d-b935-00e9be280727"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-9775ab4bce3f>\u001b[0m in \u001b[0;36m<cell line: 69>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-65-9775ab4bce3f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mradix_trie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# test_data = [\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trie' is not defined"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    radix_trie = RadixTrie()\n",
        "\n",
        "    # Add your train_data and test_data here\n",
        "    train_data = [\"CAT\", \"CAR\", \"CORN\", \"CORT\", \"CORNY\"]\n",
        "\n",
        "    # Populate trie with terms from train_data\n",
        "    for term in train_data:\n",
        "        radix_trie.insert(term)\n",
        "\n",
        "    trie.visualize()\n",
        "\n",
        "    # test_data = [\n",
        "    #     (\"PgeprjcessedgData\", \"Processed Data\"),\n",
        "    #     (\"dtae\", \"date\"),\n",
        "    #     (\"contknt\", \"contact\"),\n",
        "    #     (\"transport\", \"trdnsyort\"),\n",
        "    #     (\"wad\", \"wed\"),\n",
        "    #     # ... add more test cases\n",
        "    # ]\n",
        "\n",
        "    # radix_trie.list_all_nodes()  # List all nodes\n",
        "    # radix_trie.print_tree()  # Print tree structure\n",
        "    # radix_trie.print_statistics()  # Print statistics\n",
        "\n",
        "    # hashmap_trie = HashmapTrie()\n",
        "\n",
        "    # # Fixed weight settings (suffix_weight, similarity_weight)\n",
        "    # w2 = 0.20\n",
        "    # w3 = 1.1\n",
        "\n",
        "    # # print(\"Weight Study Results:\")\n",
        "    # # print(\"{:<10} | {:<10} | {:<10}\".format(\"w1\", \"Accuracy\", \"MMR\"))\n",
        "    # # print(\"-\" * 30)\n",
        "\n",
        "    # # Test data for evaluation\n",
        "    # test_data = [\n",
        "    #     (\"PgeprjcessedgData\", \"Processed Data\"),\n",
        "    #     (\"dtae\", \"date\"),\n",
        "    #     (\"contknt\", \"contact\"),\n",
        "    #     (\"transport\", \"trdnsyort\"),\n",
        "    #     (\"wad\", \"wed\"),\n",
        "    #     (\"projekt\", \"project\"),\n",
        "    #     # ... add more test cases\n",
        "    # ]\n",
        "\n",
        "    # # Populate trie with terms from train_data\n",
        "    # train_data = [\"Processed Data\", \"date\", \"contact\", \"trdnsyort\", \"wed\"]\n",
        "    # for term in train_data:\n",
        "    #     radix_trie.insert(term)  # Or hashmap_trie.add(term)\n",
        "    #     trie_words = radix_trie.get_all_words()  # Or hashmap_trie.get_all_words()\n",
        "    #     # print(\"Trie words:\", trie_words)\n",
        "\n",
        "    # # Varying w1 and keeping w2, w3 fixed\n",
        "    # for w1 in [0.15, 0.20, 0.25, 0.30, 0.35]:\n",
        "    #     evaluator = EvaluationPerformance(radix_trie, (w1, w2, w3))\n",
        "    #     evaluation_results = evaluator.evaluate(test_data)\n",
        "\n",
        "    #     # Extract MMR values from evaluation_results\n",
        "    #     mmr_values = [result[5] for result in evaluation_results]  # Index 5 corresponds to the MMR value\n",
        "\n",
        "    #     # Calculate average MMR value\n",
        "    #     average_mmr = sum(mmr_values) / len(mmr_values)\n",
        "\n",
        "    #     # print(\"Weight Settings: (w1 = {}, w2 = {}, w3 = {})\".format(w1, w2, w3))\n",
        "    #     # print(\"{:<10} | {:<10.3f}\".format(\"w1\", average_mmr))\n",
        "    #     # print(\"-\" * 20)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def main():\n",
        "#     # Create instances of the trie structures and the autocorrect class\n",
        "#     radix_trie = RadixTrie()\n",
        "#     hashmap_trie = HashmapTrie()\n",
        "\n",
        "#     # Fixed weight settings (suffix_weight, similarity_weight)\n",
        "#     w2 = 0.20\n",
        "#     w3 = 1.1\n",
        "\n",
        "#     print(\"Weight Study Results:\")\n",
        "#     print(\"{:<10} | {:<10} | {:<10}\".format(\"w1\", \"Accuracy\", \"MMR\"))\n",
        "#     print(\"-\" * 30)\n",
        "\n",
        "#     # Test data for evaluation\n",
        "#     test_data = [\n",
        "#         (\"PgeprjcessedgData\", \"ProcessedData\"),\n",
        "#         (\"dtae\", \"date\"),\n",
        "#         (\"contknt\", \"contact\"),\n",
        "#         (\"transport\", \"trdnsyort\"),\n",
        "#         (\"wad\", \"wed\"),\n",
        "#         # ... add more test cases\n",
        "#     ]\n",
        "\n",
        "#     # Varying w1 and keeping w2, w3 fixed\n",
        "#     # Varying w1 and keeping w2, w3 fixed\n",
        "#     for w1 in [0.15, 0.20, 0.25, 0.30, 0.35]:\n",
        "#       evaluator = EvaluationPerformance(radix_trie, (w1, w2, w3))\n",
        "#       evaluation_results = evaluator.evaluate(test_data)\n",
        "\n",
        "#       mmr_values = [result[2] for result in evaluation_results]  # Extract MMR value from result tuple\n",
        "\n",
        "#       average_mmr = sum(mmr_values) / len(mmr_values)\n",
        "\n",
        "#       print(\"Weight Settings: (w1 = {}, w2 = {}, w3 = {})\".format(w1, w2, w3))\n",
        "#       print(\"{:<10} | {:<10}\".format(\"w1\", \"MMR\"))\n",
        "#       print(\"-\" * 20)\n",
        "\n",
        "#       for result in evaluation_results:\n",
        "#         query, correct_term, overall_score, prefix_score, suffix_score, similarity_score = result\n",
        "#         # print(f\"Query: {query}, Correct Term: {correct_term}, Prefix Score: {prefix_score}, Suffix Score: {suffix_score}, Similarity Score: {similarity_score}, Overall Score: {overall_score}\")\n",
        "\n",
        "#         print(\"{:<10} | {:<10.3f}\".format(w1, result[2]))  # Use result[2] for MMR value\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "metadata": {
        "id": "SuLstq08sFLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # def evaluate(self, test_data):\n",
        "    #     accuracy_values = []\n",
        "    #     mmr_values = []\n",
        "    #     results = []\n",
        "    #     threshold = 0.7  # Set the similarity score threshold here\n",
        "\n",
        "    #     for query, correct_term in test_data:\n",
        "    #         dictionary = self.trie_structure.get_all_words()\n",
        "    #         prefix_score = self.calculate_prefix_score(query, dictionary)\n",
        "    #         suffix_score = self.calculate_suffix_score(query, dictionary)\n",
        "    #         similarity_score = self.calculate_similarity_score(query, correct_term)\n",
        "\n",
        "    #         # Calculate the overall score based on weights w1, w2, and w3\n",
        "    #         overall_score = (self.w1 * prefix_score) + (self.w2 * suffix_score) + (self.w3 * similarity_score)\n",
        "\n",
        "    #         # Calculate the predicted term based on similarity score threshold\n",
        "    #         if similarity_score >= threshold:\n",
        "    #             predicted_term = correct_term  # Use correct_term when similarity score is high\n",
        "    #         else:\n",
        "    #             predicted_term = self.trie_structure.find_most_similar_term(query)  # Replace with your method\n",
        "\n",
        "    #         accuracy = 1 if predicted_term == correct_term else 0\n",
        "    #         mmr = overall_score  # Use overall score as MMR for now\n",
        "\n",
        "    #         accuracy_values.append(accuracy)\n",
        "    #         mmr_values.append(mmr)\n",
        "\n",
        "    #     return accuracy_values, mmr_values\n",
        "\n",
        "    # def evaluate(self, test_data):\n",
        "    #   results = []\n",
        "    #   threshold = 0.7  # Set the similarity score threshold here\n",
        "\n",
        "    #   for query, correct_term in test_data:\n",
        "    #     dictionary = self.trie_structure.get_all_words()\n",
        "    #     prefix_score = self.calculate_prefix_score(query, dictionary)\n",
        "    #     suffix_score = self.calculate_suffix_score(query, dictionary)\n",
        "    #     similarity_score = self.calculate_similarity_score(query, correct_term)\n",
        "\n",
        "    #     # Calculate the predicted term based on similarity score threshold\n",
        "    #     if similarity_score >= threshold:\n",
        "    #         predicted_term = correct_term  # Use correct_term when similarity score is high\n",
        "    #     else:\n",
        "    #         predicted_term = query  # Use query when similarity score is low\n",
        "\n",
        "    #     # Calculate the overall score based on weights w1, w2, and w3\n",
        "    #     overall_score = (self.w1 * prefix_score) + (self.w2 * suffix_score) + (self.w3 * similarity_score)\n",
        "\n",
        "    #     results.append((query, correct_term, predicted_term, overall_score))\n",
        "\n",
        "    #   return results\n",
        "\n",
        "# # For debugging purposes, print the query, correct term, and similarity score\n",
        "  # print(\"Query:\", query)\n",
        "  # print(\"Correct Term:\", correct_term)\n",
        "  # print(\"Similarity Score:\", similarity_score)\n",
        "\n",
        "# Output\n",
        "# Query: PgeprjcessedgData\n",
        "# Correct Term: ProcessedData\n",
        "# Similarity Score: 0.8\n",
        "# Query: dtae\n",
        "# Correct Term: date\n",
        "# Similarity Score: 0.75\n",
        "# Query: contknt\n",
        "# Correct Term: contact\n",
        "# Similarity Score: 0.7142857142857143"
      ],
      "metadata": {
        "id": "blEBzXyiBtcz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}